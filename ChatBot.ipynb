{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sys1BykWJfLR"
      ],
      "authorship_tag": "ABX9TyMI9bbqcLaxvQu4O3VM702w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ollihansen90/ChaBoDoc_Chatbot/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ChaBoDoc-Chatbot"
      ],
      "metadata": {
        "id": "hvTTO5PJJwjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importiere Zeugs"
      ],
      "metadata": {
        "id": "QDRIssp2JppM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S3zcGKtA2m_",
        "outputId": "50235144-274d-4847-bfe3-70add9361175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['hallo', ',', 'mein', 'nam', 'ist', 'oll']\n",
            "tensor([1., 1.])\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "# Lade \n",
        "if \"google.colab\" in sys.modules:\n",
        "    if os.getcwd() == \"/content\":\n",
        "        !git clone \"https://github.com/ollihansen90/ChaBoDoc_Chatbot.git\"\n",
        "        os.chdir(\"ChaBoDoc_Chatbot\")\n",
        "\n",
        "# Importiere PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Importiere Plot-Zeugs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Natural Language Toolkit\n",
        "import nltk\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialisiere Stemmer\n",
        "STEMMER = LancasterStemmer()\n",
        "\n",
        "# Herzstück für das Textverständnis\n",
        "def bagofwords(s, words):\n",
        "    # Input: Satz s (User-Input), Liste bekannter Wörter words\n",
        "    # Output: Vektor mit Nullen und Einsen\n",
        "    bag = [0 for _ in range((len(words)))]\n",
        "    s_words = nltk.word_tokenize(s) # Splitte Satz auf in einzelne Wörter und Satzzeichen\n",
        "    s_words = [STEMMER.stem(word.lower()) for word in s_words] # \"Kürze\" Wörter gemäß Lancaster-Stemmer\n",
        "    print(s_words)\n",
        "\n",
        "    # Wenn Wort in Wortliste enthalten, setze 1, sonst 0\n",
        "    for se in s_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w==se:\n",
        "                bag[i] = 1\n",
        "        \n",
        "    return torch.tensor(bag).float() \n",
        "\n",
        "print(bagofwords(\"Hallo, mein Name ist Olli\", [\"hallo\", \"oll\"][::-1]))\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datenverarbeitung und Vorbereitung"
      ],
      "metadata": {
        "id": "0bVVS8FmJlNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from stopwords import worte\n",
        "\n",
        "with open(\"intents.json\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "words = []  # Wörter, die der Chatbot erkennen können soll\n",
        "labels = [] # zugehörige Labels (siehe Output unten)\n",
        "docs_x = [] # Trainingsgedöhns\n",
        "docs_y = []\n",
        "\n",
        "# Durchlaufe die Intents\n",
        "for intent in data[\"intents\"]:\n",
        "    # Speichere Pattern-Token (gekürzte Wörter) mit zugehörigen Labeln\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        wrds = nltk.word_tokenize(pattern)\n",
        "        words.extend(wrds)\n",
        "        docs_x.append(wrds)\n",
        "        docs_y.append(intent[\"tag\"])\n",
        "    \n",
        "    if intent[\"tag\"] not in labels:\n",
        "        labels.append(intent[\"tag\"])\n",
        "\n",
        "\"\"\"print(words)\n",
        "print(labels)\n",
        "print(docs_x)\n",
        "print(docs_y)\"\"\"\n",
        "\n",
        "words = [w for w in words if not w in worte] # Schmeiße Stopwords raus (sowas wie \"als\" oder \"habe\"), die irrelevant für die Klassifizierung sind\n",
        "words = [STEMMER.stem(w.lower()) for w in words if w != \"?\"]\n",
        "words = sorted(list(set(words)))\n",
        "labels = sorted(labels)\n",
        "print(labels)\n",
        "\n",
        "training = []\n",
        "output = []\n",
        "\n",
        "out_empty = [0 for _ in range(len(labels))]\n",
        "\n",
        "\n",
        "# Generiere training und output für Training des Chatbots\n",
        "for x, doc in enumerate(docs_x):\n",
        "    bag = []\n",
        "    wrds = [STEMMER.stem(w.lower()) for w in doc]\n",
        "\n",
        "    for w in words:\n",
        "        if w in wrds:\n",
        "            bag.append(1)\n",
        "        else:\n",
        "            bag.append(0)\n",
        "\n",
        "    output_row = out_empty[:]\n",
        "    output_row[labels.index(docs_y[x])] = 1\n",
        "    training.append(bag)\n",
        "    output.append(output_row)\n",
        "\n",
        "training = torch.tensor(training).float().to(device)\n",
        "output = torch.tensor(output).float().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWObq_dV5_dm",
        "outputId": "ef013ca3-b3b1-470a-94d4-3af04840dc6b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Corona', 'Uni', 'age', 'bad words', 'good words', 'goodbye', 'greeting', 'help', 'hobby', 'hours', 'name', 'neutral words', 'prak', 'sleep']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \"Gehirn\""
      ],
      "metadata": {
        "id": "AoZHZx6IJZHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hier sollen die Studierenden rumspielen.\n",
        "# Aktuell: Ein MLP mit einem Layer und ohne Aktivierungsfunktion\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(dim_in, dim_out)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        return out\n",
        "\n",
        "dim_in = len(training[0])\n",
        "dim_out = len(output[0])\n",
        "model = Classifier(dim_in, dim_out).to(device)\n",
        "\n",
        "print(dim_in, dim_out)"
      ],
      "metadata": {
        "id": "qpHFWYyOmF_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5fb7f8-daf8-4f93-fe8c-fdb1ee0900f1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "507 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training \"Gehirn\""
      ],
      "metadata": {
        "id": "dHoDeyFhJcHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainiere das Chatbot-Gehirn\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "n_epochs = 5000\n",
        "lossliste = torch.zeros(n_epochs)\n",
        "\n",
        "print(training.shape, output.shape)\n",
        "# Da der Datensatz nur 525 Einträge enthält, brauchen wir keine Batches und können komplett trainieren\n",
        "for epoch in range(n_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(training)\n",
        "    loss = loss_func(out, output)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    lossliste[epoch] = loss.item()\n",
        "    if epoch%int(n_epochs/10)==0:\n",
        "        print(epoch, loss.item())\n",
        "\n",
        "# Plotte Loss-Verlauf\n",
        "plt.figure()\n",
        "plt.plot(lossliste.cpu().numpy())\n",
        "plt.title(\"Trainingsloss\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "913Tt2Atmy6P",
        "outputId": "6ad65c6b-315f-463d-866b-08bb61c7883b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([525, 507]) torch.Size([525, 14])\n",
            "0 2.6530797481536865\n",
            "500 1.2560242414474487\n",
            "1000 0.6387110948562622\n",
            "1500 0.36530399322509766\n",
            "2000 0.23109039664268494\n",
            "2500 0.15723304450511932\n",
            "3000 0.11277838051319122\n",
            "3500 0.08420458436012268\n",
            "4000 0.06493925303220749\n",
            "4500 0.051480233669281006\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verarbeite Input"
      ],
      "metadata": {
        "id": "nySuaqRWMoSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import choice\n",
        "\n",
        "# Wende Chatbot-Gehirn auf Nachricht an\n",
        "def predict(message, model, words, labels, data):\n",
        "    message = message.lower()\n",
        "    result = F.softmax(model(bagofwords(message, words).to(device)), dim=0)\n",
        "    result_index = torch.argmax(result)\n",
        "    tag = labels[result_index]\n",
        "\n",
        "    # Wie sicher ist sich der Chatbot? 0.9 ist schon ziemlich sicher.\n",
        "    if result[result_index] > 0.9:\n",
        "        for tg in data[\"intents\"]:\n",
        "            if tg[\"tag\"] == tag:\n",
        "                responses = tg[\"responses\"]\n",
        "        response = choice(responses)\n",
        "    else:\n",
        "        print(\"Chatbot ist sich etwas unsicher.\", result[result_index].item())\n",
        "        response = \"Come again for Big Fudge?\"\n",
        "    return tag, response, result[result_index].item()"
      ],
      "metadata": {
        "id": "g3tg_CSzMrNS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verständnistest"
      ],
      "metadata": {
        "id": "Br5LQ-8YLKxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Versetze Modell in Evaluationsmodus\n",
        "model.eval()\n",
        "\n",
        "# Interaktion 1: Begrüßung\n",
        "print(\"Chatbot:\", \"Hallo :-)\")\n",
        "user_input = input(\"User:    \")\n",
        "tag, response, sicher= predict(user_input, model, words, labels, data)\n",
        "print(\"Chatbot glaubt, das Label ist\", tag, sicher)\n",
        "print(\"Chatbot:\", response)\n",
        "\n",
        "# Interaktion 2: Whaddup\n",
        "print(\"Chatbot:\", \"Wie geht es dir?\")\n",
        "user_input = input(\"User:    \")\n",
        "tag, response, sicher = predict(user_input, model, words, labels, data)\n",
        "print(\"Chatbot glaubt, das Label ist\", tag, sicher)\n",
        "print(\"Chatbot:\", response)\n",
        "\n",
        "# Interaktion 3: Verabschiedung\n",
        "print(\"Chatbot:\", \"Ich muss jetzt leider gehen... Auf Wiedersehen :-)\")\n",
        "user_input = input(\"User:    \")\n",
        "tag, response, sicher = predict(user_input, model, words, labels, data)\n",
        "print(\"Chatbot glaubt, das Label ist\", tag, sicher)\n",
        "print(\"Chatbot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0akVvUOLKPJ",
        "outputId": "9e87716f-bbf8-4cbc-dfc8-2dffddd81f1f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: Hallo :-)\n",
            "User:    Hi\n",
            "['hi']\n",
            "Chatbot glaubt, das Label ist greeting 0.9614651799201965\n",
            "Chatbot: Es freut mich, Dich hier zu treffen!\n",
            "Chatbot: Wie geht es dir?\n",
            "User:    sehr gut\n",
            "['sehr', 'gut']\n",
            "Chatbot glaubt, das Label ist good words 0.9795877933502197\n",
            "Chatbot: Ich bin heute auch super drauf!\n",
            "Chatbot: Ich muss jetzt leider gehen... Auf Wiedersehen :-)\n",
            "User:    bis bald\n",
            "['bis', 'bald']\n",
            "Chatbot glaubt, das Label ist goodbye 0.9954853653907776\n",
            "Chatbot: Schade, dass Du schon gehen musst!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alte Tests"
      ],
      "metadata": {
        "id": "sys1BykWJfLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import urllib.request\n",
        "with urllib.request.urlopen(\"https://raw.githubusercontent.com/inb-luebeck/chat_bot/main/Melinda/intents.json?token=GHSAT0AAAAAABQNOK46CRADPTF4EY5NRSGWYO4D7XA\") as file:\n",
        "    data = json.loads(file.read().decode())\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "6Z8Ddvs61WjF",
        "outputId": "7dfc1fb3-b521-46b7-f310-ff728360d695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-584ffae0b01e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://raw.githubusercontent.com/inb-luebeck/chat_bot/main/Melinda/intents.json?token=GHSAT0AAAAAABQNOK46CRADPTF4EY5NRSGWYO4D7XA\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import cloudpickle as cp\n",
        "\n",
        "loaded_pickle_object = cp.load(urllib.request.urlopen(\"https://github.com/inb-luebeck/chat_bot/blob/main/Melinda/model/data.pickle?raw=true\", \"rb\"))\n",
        "print(loaded_pickle_object)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "mFaN0aMS3gQ4",
        "outputId": "2a9ba27a-146b-4445-80dd-66c8cd5fffd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-dac9f8e83bae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcloudpickle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloaded_pickle_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://github.com/inb-luebeck/chat_bot/blob/main/Melinda/model/data.pickle?raw=true\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_pickle_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_request_\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1278\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"POST data should be bytes, an iterable of bytes, \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m                       \u001b[0;34m\"or a file object. It cannot be of type str.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Content-type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m                 request.add_unredirected_header(\n",
            "\u001b[0;31mTypeError\u001b[0m: POST data should be bytes, an iterable of bytes, or a file object. It cannot be of type str."
          ]
        }
      ]
    }
  ]
}