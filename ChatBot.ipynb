{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sys1BykWJfLR"
      ],
      "authorship_tag": "ABX9TyPgQN/px4FZ18ivcFLgOcmA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ollihansen90/ChaBoDoc_Chatbot/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ChaBoDoc-Chatbot"
      ],
      "metadata": {
        "id": "hvTTO5PJJwjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importiere Zeugs"
      ],
      "metadata": {
        "id": "QDRIssp2JppM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S3zcGKtA2m_",
        "outputId": "7ee221fe-3c3a-4df7-8c90-6e26b093d0ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['hallo', ',', 'mein', 'nam', 'ist', 'oll']\n",
            "tensor([1., 1.])\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "# Lade \n",
        "if \"google.colab\" in sys.modules:\n",
        "    if os.getcwd() == \"/content\":\n",
        "        !git clone \"https://github.com/ollihansen90/ChaBoDoc_Chatbot.git\"\n",
        "        os.chdir(\"ChaBoDoc_Chatbot\")\n",
        "\n",
        "# Importiere PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Importiere Plot-Zeugs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Natural Language Toolkit\n",
        "import nltk\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialisiere Stemmer\n",
        "STEMMER = LancasterStemmer()\n",
        "\n",
        "# Herzstück für das Textverständnis\n",
        "def bagofwords(s, words):\n",
        "    # Input: Satz s (User-Input), Liste bekannter Wörter words\n",
        "    # Output: Vektor mit Nullen und Einsen\n",
        "    bag = [0 for _ in range((len(words)))]\n",
        "    s_words = nltk.word_tokenize(s) # Splitte Satz auf in einzelne Wörter und Satzzeichen\n",
        "    s_words = [STEMMER.stem(word.lower()) for word in s_words] # \"Kürze\" Wörter gemäß Lancaster-Stemmer\n",
        "    print(s_words)\n",
        "\n",
        "    # Wenn Wort in Wortliste enthalten, setze 1, sonst 0\n",
        "    for se in s_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w==se:\n",
        "                bag[i] = 1\n",
        "        \n",
        "    return torch.tensor(bag).float() \n",
        "\n",
        "print(bagofwords(\"Hallo, mein Name ist Olli\", [\"hallo\", \"oll\"][::-1]))\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datenverarbeitung und Vorbereitung"
      ],
      "metadata": {
        "id": "0bVVS8FmJlNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from stopwords import worte\n",
        "\n",
        "with open(\"intents.json\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "words = []  # Wörter, die der Chatbot erkennen können soll\n",
        "labels = [] # zugehörige Labels (siehe Output unten)\n",
        "docs_x = [] # Trainingsgedöhns\n",
        "docs_y = []\n",
        "\n",
        "# Durchlaufe die Intents\n",
        "for intent in data[\"intents\"]:\n",
        "    # Speichere Pattern-Token (gekürzte Wörter) mit zugehörigen Labeln\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        wrds = nltk.word_tokenize(pattern)\n",
        "        words.extend(wrds)\n",
        "        docs_x.append(wrds)\n",
        "        docs_y.append(intent[\"tag\"])\n",
        "    \n",
        "    if intent[\"tag\"] not in labels:\n",
        "        labels.append(intent[\"tag\"])\n",
        "\n",
        "\"\"\"print(words)\n",
        "print(labels)\n",
        "print(docs_x)\n",
        "print(docs_y)\"\"\"\n",
        "\n",
        "words = [w for w in words if not w in worte] # Schmeiße Stopwords raus (sowas wie \"als\" oder \"habe\"), die irrelevant für die Klassifizierung sind\n",
        "words = [STEMMER.stem(w.lower()) for w in words if w != \"?\"]\n",
        "words = sorted(list(set(words)))\n",
        "labels = sorted(labels)\n",
        "print(labels)\n",
        "\n",
        "training = []\n",
        "output = []\n",
        "\n",
        "out_empty = [0 for _ in range(len(labels))]\n",
        "\n",
        "\n",
        "# Generiere training und output für Training des Chatbots\n",
        "for x, doc in enumerate(docs_x):\n",
        "    bag = []\n",
        "    wrds = [STEMMER.stem(w.lower()) for w in doc]\n",
        "\n",
        "    for w in words:\n",
        "        if w in wrds:\n",
        "            bag.append(1)\n",
        "        else:\n",
        "            bag.append(0)\n",
        "\n",
        "    output_row = out_empty[:]\n",
        "    output_row[labels.index(docs_y[x])] = 1\n",
        "    training.append(bag)\n",
        "    output.append(output_row)\n",
        "\n",
        "training = torch.tensor(training).float().to(device)\n",
        "output = torch.tensor(output).float().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWObq_dV5_dm",
        "outputId": "3dada1b8-f741-4dee-9c0f-6f116ade2e18"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Corona', 'Uni', 'age', 'bad words', 'good words', 'goodbye', 'greeting', 'help', 'hobby', 'hours', 'name', 'neutral words', 'prak', 'sleep']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \"Gehirn\""
      ],
      "metadata": {
        "id": "AoZHZx6IJZHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hier sollen die Studierenden rumspielen.\n",
        "# Aktuell: Ein MLP mit einem Layer und ohne Aktivierungsfunktion\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(dim_in, dim_out)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        return out\n",
        "\n",
        "dim_in = len(training[0])\n",
        "dim_out = len(output[0])\n",
        "model = Classifier(dim_in, dim_out).to(device)\n",
        "\n",
        "print(dim_in, dim_out)"
      ],
      "metadata": {
        "id": "qpHFWYyOmF_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "809f8746-e86d-4b2b-d4e9-76e2ae101b8c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "507 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training \"Gehirn\""
      ],
      "metadata": {
        "id": "dHoDeyFhJcHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainiere das Chatbot-Gehirn\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "n_epochs = 5000\n",
        "lossliste = torch.zeros(n_epochs)\n",
        "\n",
        "print(training.shape, output.shape)\n",
        "# Da der Datensatz nur 525 Einträge enthält, brauchen wir keine Batches und können komplett trainieren\n",
        "for epoch in range(n_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(training)\n",
        "    loss = loss_func(out, output)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    lossliste[epoch] = loss.item()\n",
        "    if epoch%100==0:\n",
        "        print(epoch, loss.item())\n",
        "\n",
        "# Plotte Loss-Verlauf\n",
        "plt.figure()\n",
        "plt.plot(lossliste.cpu().numpy())\n",
        "plt.title(\"Trainingsloss\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "913Tt2Atmy6P",
        "outputId": "c0c179b1-69ec-4a9d-d994-3ed750520496"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([525, 507]) torch.Size([525, 14])\n",
            "0 2.6438634395599365\n",
            "100 2.281384229660034\n",
            "200 1.961513876914978\n",
            "300 1.6856215000152588\n",
            "400 1.450934648513794\n",
            "500 1.2524813413619995\n",
            "600 1.084957242012024\n",
            "700 0.9435493350028992\n",
            "800 0.8241119384765625\n",
            "900 0.7231124639511108\n",
            "1000 0.6375419497489929\n",
            "1100 0.5648451447486877\n",
            "1200 0.5028663277626038\n",
            "1300 0.4498037099838257\n",
            "1400 0.40416374802589417\n",
            "1500 0.364716112613678\n",
            "1600 0.3304513096809387\n",
            "1700 0.30054202675819397\n",
            "1800 0.27430960536003113\n",
            "1900 0.2511962950229645\n",
            "2000 0.23074188828468323\n",
            "2100 0.21256518363952637\n",
            "2200 0.19634900987148285\n",
            "2300 0.181828111410141\n",
            "2400 0.16877976059913635\n",
            "2500 0.15701603889465332\n",
            "2600 0.1463775634765625\n",
            "2700 0.13672874867916107\n",
            "2800 0.12795360386371613\n",
            "2900 0.11995261162519455\n",
            "3000 0.11263994127511978\n",
            "3100 0.10594133287668228\n",
            "3200 0.09979227185249329\n",
            "3300 0.09413648396730423\n",
            "3400 0.08892470598220825\n",
            "3500 0.084113709628582\n",
            "3600 0.07966534048318863\n",
            "3700 0.07554587721824646\n",
            "3800 0.07172540575265884\n",
            "3900 0.06817731261253357\n",
            "4000 0.06487784534692764\n",
            "4100 0.06180575489997864\n",
            "4200 0.05894199386239052\n",
            "4300 0.05626944452524185\n",
            "4400 0.05377265438437462\n",
            "4500 0.05143769830465317\n",
            "4600 0.0492519736289978\n",
            "4700 0.04720405116677284\n",
            "4800 0.04528355970978737\n",
            "4900 0.04348105192184448\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verarbeite Input"
      ],
      "metadata": {
        "id": "nySuaqRWMoSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import choice\n",
        "\n",
        "# Wende Chatbot-Gehirn auf Nachricht an\n",
        "def predict(message, model, words, labels, data):\n",
        "    message = message.lower()\n",
        "    result = F.softmax(model(bagofwords(message, words).to(device)), dim=0)\n",
        "    result_index = torch.argmax(result)\n",
        "    tag = labels[result_index]\n",
        "\n",
        "    # Wie sicher ist sich der Chatbot? 0.9 ist schon ziemlich sicher.\n",
        "    if result[result_index] > 0.9:\n",
        "        for tg in data[\"intents\"]:\n",
        "            if tg[\"tag\"] == tag:\n",
        "                responses = tg[\"responses\"]\n",
        "        response = choice(responses)\n",
        "    else:\n",
        "        print(\"Chatbot ist sich etwas unsicher.\", result[result_index].item())\n",
        "        response = \"Come again for Big Fudge?\"\n",
        "    return tag, response"
      ],
      "metadata": {
        "id": "g3tg_CSzMrNS"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verständnistest"
      ],
      "metadata": {
        "id": "Br5LQ-8YLKxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Versetze Modell in Evaluationsmodus\n",
        "model.eval()\n",
        "\n",
        "# Interaktion 1: Begrüßung\n",
        "print(\"Chatbot:\", \"Hallo :-)\")\n",
        "user_input = input(\"User:    \")\n",
        "tag, response = predict(user_input, model, words, labels, data)\n",
        "print(\"Chatbot glaubt, das Label ist\", tag)\n",
        "print(\"Chatbot:\", response)\n",
        "\n",
        "# Interaktion 2: Whaddup\n",
        "print(\"Chatbot:\", \"Wie geht es dir?\")\n",
        "user_input = input(\"User:    \")\n",
        "tag, response = predict(user_input, model, words, labels, data)\n",
        "print(\"Chatbot glaubt, das Label ist\", tag)\n",
        "print(\"Chatbot:\", response)\n",
        "\n",
        "# Interaktion 3: Verabschiedung\n",
        "print(\"Chatbot:\", \"Ich muss jetzt leider gehen... Auf Wiedersehen :-)\")\n",
        "user_input = input(\"User:    \")\n",
        "tag, response = predict(user_input, model, words, labels, data)\n",
        "print(\"Chatbot glaubt, das Label ist\", tag)\n",
        "print(\"Chatbot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0akVvUOLKPJ",
        "outputId": "9e0c8daa-85ce-482d-a078-d3a6c98b37c0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: Hallo :-)\n",
            "User:    Huhu\n",
            "['huhu']\n",
            "Chatbot glaubt, das Label ist greeting\n",
            "Chatbot: Hi, wie kann ich Dir helfen?\n",
            "Chatbot: Wie geht es dir?\n",
            "User:    Gut, und dir?\n",
            "['gut', ',', 'und', 'dir', '?']\n",
            "Chatbot glaubt, das Label ist goodbye\n",
            "Chatbot: Bis bald dann mal!\n",
            "Chatbot: Ich muss jetzt leider gehen... Auf Wiedersehen :-)\n",
            "User:    Bis dann\n",
            "['bis', 'dan']\n",
            "Chatbot glaubt, das Label ist goodbye\n",
            "Chatbot: Bis bald dann mal!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alte Tests"
      ],
      "metadata": {
        "id": "sys1BykWJfLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import urllib.request\n",
        "with urllib.request.urlopen(\"https://raw.githubusercontent.com/inb-luebeck/chat_bot/main/Melinda/intents.json?token=GHSAT0AAAAAABQNOK46CRADPTF4EY5NRSGWYO4D7XA\") as file:\n",
        "    data = json.loads(file.read().decode())\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "6Z8Ddvs61WjF",
        "outputId": "7dfc1fb3-b521-46b7-f310-ff728360d695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-584ffae0b01e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://raw.githubusercontent.com/inb-luebeck/chat_bot/main/Melinda/intents.json?token=GHSAT0AAAAAABQNOK46CRADPTF4EY5NRSGWYO4D7XA\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import cloudpickle as cp\n",
        "\n",
        "loaded_pickle_object = cp.load(urllib.request.urlopen(\"https://github.com/inb-luebeck/chat_bot/blob/main/Melinda/model/data.pickle?raw=true\", \"rb\"))\n",
        "print(loaded_pickle_object)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "mFaN0aMS3gQ4",
        "outputId": "2a9ba27a-146b-4445-80dd-66c8cd5fffd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-dac9f8e83bae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcloudpickle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloaded_pickle_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://github.com/inb-luebeck/chat_bot/blob/main/Melinda/model/data.pickle?raw=true\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_pickle_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_request_\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1278\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"POST data should be bytes, an iterable of bytes, \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m                       \u001b[0;34m\"or a file object. It cannot be of type str.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Content-type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m                 request.add_unredirected_header(\n",
            "\u001b[0;31mTypeError\u001b[0m: POST data should be bytes, an iterable of bytes, or a file object. It cannot be of type str."
          ]
        }
      ]
    }
  ]
}